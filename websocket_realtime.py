#!/usr/bin/env python3
"""
WebSocket å³æ™‚äººè‡‰è­˜åˆ¥ç³»çµ±
æ”¯æ´æ”åƒé ­ä¸²æµå’Œå³æ™‚è¾¨è­˜
"""

import asyncio
import websockets
import json
import base64
import cv2
import numpy as np
from PIL import Image
import io
import time
from datetime import datetime
from database_manager import PostgresFaceDatabase
from insightface.app import FaceAnalysis
from huggingface_hub import snapshot_download
import os

# ç¢ºä¿æ¨¡å‹å­˜åœ¨
if not os.path.exists("models/auraface"):
    print("æ­£åœ¨ä¸‹è¼‰ AuraFace æ¨¡å‹...")
    snapshot_download("fal/AuraFace-v1", local_dir="models/auraface")

# åˆå§‹åŒ– AuraFace
print("åˆå§‹åŒ– AuraFace...")
face_app = FaceAnalysis(
    name="auraface",
    providers=["CPUExecutionProvider"],
    root=".",
)
face_app.prepare(ctx_id=0, det_size=(640, 640))

# åˆå§‹åŒ–è³‡æ–™åº«
face_db = PostgresFaceDatabase()

class RealtimeFaceRecognition:
    def __init__(self):
        self.connected_clients = set()
        self.recognition_stats = {
            'total_frames': 0,
            'faces_detected': 0,
            'employees_detected': 0,
            'visitors_detected': 0,
            'unknown_detected': 0
        }
    
    async def register(self, websocket, path):
        """è¨»å†Šæ–°çš„ WebSocket é€£æ¥"""
        self.connected_clients.add(websocket)
        print(f"æ–°å®¢æˆ¶ç«¯é€£æ¥: {websocket.remote_address}")
        
        try:
            await websocket.send(json.dumps({
                'type': 'connection_status',
                'status': 'connected',
                'message': 'å·²é€£æ¥åˆ°å³æ™‚äººè‡‰è­˜åˆ¥ç³»çµ±'
            }))
            
            await self.handle_client(websocket)
        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            self.connected_clients.remove(websocket)
            print(f"å®¢æˆ¶ç«¯æ–·ç·š: {websocket.remote_address}")
    
    async def handle_client(self, websocket):
        """è™•ç†å®¢æˆ¶ç«¯è¨Šæ¯"""
        async for message in websocket:
            try:
                data = json.loads(message)
                await self.process_message(websocket, data)
            except Exception as e:
                await websocket.send(json.dumps({
                    'type': 'error',
                    'message': f'è¨Šæ¯è™•ç†éŒ¯èª¤: {str(e)}'
                }))
    
    async def process_message(self, websocket, data):
        """è™•ç†ä¸åŒé¡å‹çš„è¨Šæ¯"""
        message_type = data.get('type')
        
        if message_type == 'video_frame':
            await self.process_video_frame(websocket, data)
        elif message_type == 'get_stats':
            await self.send_stats(websocket)
        elif message_type == 'register_face':
            await self.register_new_face(websocket, data)
        else:
            await websocket.send(json.dumps({
                'type': 'error',
                'message': f'æœªçŸ¥è¨Šæ¯é¡å‹: {message_type}'
            }))
    
    async def process_video_frame(self, websocket, data):
        """è™•ç†è¦–è¨Šå¹€ä¸¦é€²è¡Œäººè‡‰è­˜åˆ¥"""
        try:
            # è§£æ base64 åœ–ç‰‡
            image_data = data.get('image')
            if not image_data:
                return
            
            # ç§»é™¤ data:image/jpeg;base64, å‰ç¶´
            if ',' in image_data:
                image_data = image_data.split(',')[1]
            
            # è§£ç¢¼åœ–ç‰‡
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # è½‰æ›ç‚º CV2 æ ¼å¼
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # é€²è¡Œäººè‡‰è­˜åˆ¥
            start_time = time.time()
            results = await self.identify_faces_async(cv_image)
            processing_time = time.time() - start_time
            
            # æ›´æ–°çµ±è¨ˆ
            self.recognition_stats['total_frames'] += 1
            if results:
                self.recognition_stats['faces_detected'] += len(results)
                for result in results:
                    if result['role'] == 'å“¡å·¥':
                        self.recognition_stats['employees_detected'] += 1
                    elif result['person_id'] == 'unknown':
                        self.recognition_stats['unknown_detected'] += 1
                    else:
                        self.recognition_stats['visitors_detected'] += 1
            
            # åœ¨åœ–ç‰‡ä¸Šç¹ªè£½çµæœ
            annotated_image = self.draw_annotations(cv_image, results)
            
            # è½‰æ›å› base64
            _, buffer = cv2.imencode('.jpg', annotated_image)
            annotated_b64 = base64.b64encode(buffer).decode('utf-8')
            
            # ç™¼é€çµæœ
            response = {
                'type': 'recognition_result',
                'image': f'data:image/jpeg;base64,{annotated_b64}',
                'faces': results,
                'processing_time': round(processing_time * 1000, 2),  # ms
                'fps': round(1 / processing_time, 1) if processing_time > 0 else 0,
                'timestamp': datetime.now().isoformat()
            }
            
            await websocket.send(json.dumps(response))
            
        except Exception as e:
            await websocket.send(json.dumps({
                'type': 'error',
                'message': f'åœ–ç‰‡è™•ç†éŒ¯èª¤: {str(e)}'
            }))
    
    async def identify_faces_async(self, cv_image):
        """éåŒæ­¥äººè‡‰è­˜åˆ¥"""
        try:
            # åŸ·è¡Œäººè‡‰æª¢æ¸¬
            faces = face_app.get(cv_image)
            
            if not faces:
                return []
            
            results = []
            for face in faces:
                # åœ¨è³‡æ–™åº«ä¸­æœå°‹ç›¸ä¼¼äººè‡‰
                matches = face_db.find_similar_faces(face.normed_embedding, threshold=0.6)
                
                if matches:
                    best_match = matches[0]
                    # è¨˜éŒ„è­˜åˆ¥æ—¥èªŒ
                    face_db.log_recognition(
                        best_match['person_id'], 
                        best_match['name'], 
                        best_match['confidence'], 
                        "websocket_stream"
                    )
                    
                    results.append({
                        'bbox': face.bbox.tolist(),
                        'person_id': best_match['person_id'],
                        'name': best_match['name'],
                        'role': best_match['role'],
                        'department': best_match['department'],
                        'confidence': best_match['confidence']
                    })
                else:
                    results.append({
                        'bbox': face.bbox.tolist(),
                        'person_id': 'unknown',
                        'name': '',
                        'role': '',
                        'department': '',
                        'confidence': 0.0
                    })
            
            return results
            
        except Exception as e:
            print(f"è­˜åˆ¥éŒ¯èª¤: {e}")
            return []
    
    def draw_annotations(self, cv_image, results):
        """åœ¨åœ–ç‰‡ä¸Šç¹ªè£½è­˜åˆ¥çµæœ"""
        annotated = cv_image.copy()
        
        for result in results:
            bbox = [int(x) for x in result['bbox']]
            x1, y1, x2, y2 = bbox
            
            # æ ¹æ“šèº«åˆ†é¸æ“‡é¡è‰²å’Œæ˜¯å¦é¡¯ç¤ºæ¨™ç±¤
            if result['person_id'] == 'unknown':
                # æœªè­˜åˆ¥çš„äººè‡‰ï¼šç´…è‰²æ¡†ï¼Œä¸é¡¯ç¤ºä»»ä½•æ–‡å­—
                color = (0, 0, 255)  # ç´…è‰²
                show_label = False
            elif result['role'] == 'å“¡å·¥':
                # å·²è­˜åˆ¥å“¡å·¥ï¼šç¶ è‰²æ¡†ï¼Œé¡¯ç¤ºå®Œæ•´æ¨™ç±¤
                color = (0, 255, 0)  # ç¶ è‰²
                show_label = True
            elif result['role'] == 'è¨ªå®¢':
                # å·²è­˜åˆ¥è¨ªå®¢ï¼šé»ƒè‰²æ¡†ï¼Œé¡¯ç¤ºå®Œæ•´æ¨™ç±¤
                color = (0, 255, 255)  # é»ƒè‰²
                show_label = True
            else:
                # å…¶ä»–æƒ…æ³ï¼šç´…è‰²æ¡†ï¼Œä¸é¡¯ç¤ºæ¨™ç±¤
                color = (0, 0, 255)  # ç´…è‰²
                show_label = False
            
            # ç•«äººè‡‰æ¡†
            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
            
            # åªæœ‰å·²è­˜åˆ¥çš„äººè‡‰æ‰é¡¯ç¤ºæ¨™ç±¤
            if show_label and result['person_id'] != 'unknown':
                # æº–å‚™æ¨™ç±¤æ–‡å­—
                label = f"{result['name']}"
                # å°‡ä¸­æ–‡è§’è‰²è½‰æ›ç‚ºè‹±æ–‡
                role_mapping = {'å“¡å·¥': 'Staff', 'è¨ªå®¢': 'Visitor'}
                role_text = f"[{role_mapping.get(result['role'], result['role'])}]"
                conf_text = f"{result['confidence']:.2f}"
                
                # è¨ˆç®—æ¨™ç±¤èƒŒæ™¯å¤§å°
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                role_size = cv2.getTextSize(role_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                max_width = max(label_size[0], role_size[0]) + 10
                
                # ç•«æ¨™ç±¤èƒŒæ™¯
                cv2.rectangle(annotated, (x1, y1-60), (x1 + max_width, y1), color, -1)
                
                # ç•«æ–‡å­—
                cv2.putText(annotated, role_text, (x1 + 5, y1 - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                cv2.putText(annotated, label, (x1 + 5, y1 - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                cv2.putText(annotated, conf_text, (x1 + 5, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        return annotated
    
    async def send_stats(self, websocket):
        """ç™¼é€çµ±è¨ˆè³‡æ–™"""
        response = {
            'type': 'stats',
            'data': self.recognition_stats
        }
        await websocket.send(json.dumps(response))
    
    async def register_new_face(self, websocket, data):
        """è¨»å†Šæ–°äººè‡‰"""
        try:
            name = data.get('name')
            role = data.get('role')
            department = data.get('department', '')
            image_data = data.get('image')
            
            if not all([name, role, image_data]):
                await websocket.send(json.dumps({
                    'type': 'register_result',
                    'success': False,
                    'message': 'ç¼ºå°‘å¿…è¦è³‡æ–™'
                }))
                return
            
            # è§£ç¢¼åœ–ç‰‡
            if ',' in image_data:
                image_data = image_data.split(',')[1]
            
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # æª¢æ¸¬äººè‡‰
            faces = face_app.get(cv_image)
            
            if len(faces) == 0:
                await websocket.send(json.dumps({
                    'type': 'register_result',
                    'success': False,
                    'message': 'æœªæª¢æ¸¬åˆ°äººè‡‰'
                }))
                return
            
            if len(faces) > 1:
                await websocket.send(json.dumps({
                    'type': 'register_result',
                    'success': False,
                    'message': 'æª¢æ¸¬åˆ°å¤šå¼µäººè‡‰'
                }))
                return
            
            # è¨»å†Šäººè‡‰
            embedding = faces[0].normed_embedding
            success, message = face_db.register_face(name, role, department, embedding)
            
            await websocket.send(json.dumps({
                'type': 'register_result',
                'success': success,
                'message': message
            }))
            
        except Exception as e:
            await websocket.send(json.dumps({
                'type': 'register_result',
                'success': False,
                'message': f'è¨»å†ŠéŒ¯èª¤: {str(e)}'
            }))

async def main():
    """å•Ÿå‹• WebSocket ä¼ºæœå™¨"""
    recognizer = RealtimeFaceRecognition()
    
    print("ğŸš€ å•Ÿå‹• WebSocket å³æ™‚äººè‡‰è­˜åˆ¥ä¼ºæœå™¨...")
    print("ğŸ“¡ WebSocket ä¼ºæœå™¨ä½å€: ws://localhost:8765")
    
    start_server = websockets.serve(
        recognizer.register, 
        "0.0.0.0", 
        8765,
        max_size=10 * 1024 * 1024,  # 10MB æ¶ˆæ¯å¤§å°é™åˆ¶
        ping_interval=20,
        ping_timeout=10
    )
    
    await start_server
    print("âœ… WebSocket ä¼ºæœå™¨å·²å•Ÿå‹•")
    
    # ä¿æŒä¼ºæœå™¨é‹è¡Œ
    await asyncio.Future()  # run forever

if __name__ == "__main__":
    asyncio.run(main())